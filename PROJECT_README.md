# Secure Code Generation - SQL Injection Vulnerability Experiment

A comprehensive experiment to test whether **GPT-3.5-turbo generates SQL code vulnerable to SQL injection attacks**.

## ğŸ¯ Objective

Determine the prevalence and types of SQL injection vulnerabilities in SQL code generated by GPT-3.5-turbo when given natural language prompts.

## ğŸ”¬ Experiment Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Experiment Workflow                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Claude 3.5 Sonnet                                         â”‚
â”‚  â†“                                                          â”‚
â”‚  Generate 20 natural language prompts for SQL              â”‚
â”‚  â†“                                                          â”‚
â”‚  [20 diverse SQL task descriptions]                        â”‚
â”‚  â†“                                                          â”‚
â”‚  GPT-3.5-turbo                                             â”‚
â”‚  â†“                                                          â”‚
â”‚  Generate SQL code for each prompt                         â”‚
â”‚  â†“                                                          â”‚
â”‚  [20 SQL code samples]                                     â”‚
â”‚  â†“                                                          â”‚
â”‚  Claude 3.5 Sonnet                                         â”‚
â”‚  â†“                                                          â”‚
â”‚  Analyze each SQL for CWE vulnerabilities                  â”‚
â”‚  â†“                                                          â”‚
â”‚  [Verdict + CWE ID for each sample]                        â”‚
â”‚  â†“                                                          â”‚
â”‚  Generate Visualizations                                   â”‚
â”‚  â†“                                                          â”‚
â”‚  [Charts, tables, detailed report]                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Key Findings (After Running)

The experiment will reveal:
- **Vulnerability Rate**: % of GPT-generated SQL with injection flaws
- **CWE Distribution**: Common vulnerability types
- **Code Patterns**: Safe vs unsafe SQL generation patterns
- **Practical Insights**: Real risks when using LLMs for SQL generation

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- API keys for Claude (Anthropic) and OpenAI

### 1. Clone & Setup

```bash
cd md-vuln-markdown-generator
cp .env.example .env
nano .env  # Add your API keys
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Experiment

```bash
# Quick start with 20 samples
python -m src.experiment_main

# Or specify custom number of samples
python -m src.experiment_main 50

# Or use the quick start script
bash quickstart.sh
```

### 4. View Results

Results are saved to `experiments/` directory:
- `experiment_results.json` - Raw data
- `REPORT.md` - Detailed markdown report
- `*.png` - Visualizations (charts and statistics)

## ğŸ“ Project Structure

```
md-vuln-markdown-generator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ claude_client.py          # Claude API integration
â”‚   â”‚   â””â”€â”€ openai_client.py          # OpenAI API integration
â”‚   â”œâ”€â”€ experiment_runner.py          # Core experiment logic
â”‚   â”œâ”€â”€ experiment_main.py            # CLI entry point
â”‚   â”œâ”€â”€ visualizations.py             # Chart/graph generation
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ io.py                     # I/O utilities
â”œâ”€â”€ experiments/                      # Output directory (created at runtime)
â”‚   â”œâ”€â”€ README.md                     # Detailed experiment guide
â”‚   â”œâ”€â”€ experiment_results.json       # Raw results (generated)
â”‚   â”œâ”€â”€ REPORT.md                     # Report (generated)
â”‚   â””â”€â”€ *.png                         # Visualizations (generated)
â”œâ”€â”€ .env                              # API keys (create from .env.example)
â”œâ”€â”€ .env.example                      # Environment template
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ quickstart.sh                     # Quick start script
â””â”€â”€ README.md                         # This file
```

## ğŸ”‘ API Configuration

### Claude (Anthropic)
1. Get key from: https://console.anthropic.com/account/keys
2. Add to `.env` as: `CLAUDE_API_KEY=sk-ant-...`
3. Model used: `claude-3-5-sonnet-20241022`

### OpenAI
1. Get key from: https://platform.openai.com/account/api-keys
2. Add to `.env` as: `OPENAI_API_KEY=sk-...`
3. Model used: `gpt-3.5-turbo`

## ğŸ“ˆ Output Visualizations

The experiment generates:

1. **Vulnerability Distribution** (Pie chart)
   - Shows % of vulnerable vs safe SQL code

2. **CWE Distribution** (Bar chart)
   - Common vulnerability types found

3. **Summary Statistics** (Info graphic)
   - Key metrics and findings

4. **Sample Showcase** (Multi-panel)
   - Examples of vulnerable and safe code

## ğŸ›¡ï¸ Understanding Results

### Verdict Categories

| Verdict | Meaning |
|---------|---------|
| **VULNERABLE** | Potential SQL injection detected |
| **NOT VULNERABLE** | Code appears safe from injection |
| **ERROR** | Analysis could not complete |

### Common CWE IDs

| CWE | Type | Risk |
|-----|------|------|
| **CWE-89** | SQL Injection | Critical |
| **CWE-564** | SQL Injection (variant) | Critical |
| **CWE-90** | Improper Neutralization | High |

## ğŸ› Troubleshooting

### "API key not found"
```bash
# Ensure .env file exists and has keys
cat .env | grep CLAUDE_API_KEY
cat .env | grep OPENAI_API_KEY
```

### "Module not found"
```bash
# Install dependencies
pip install -r requirements.txt

# Run from project root with -m flag
python -m src.experiment_main
```

### "Rate limit exceeded"
```bash
# Try again later or reduce sample size
python -m src.experiment_main 5
```

### "Matplotlib not found"
```bash
# Install optional visualization dependencies
pip install matplotlib
```

## ğŸ“š Understanding SQL Injection

### Vulnerable Pattern
```sql
-- BAD: User input directly in query
SELECT * FROM users WHERE email = 'user@example.com OR 1=1 --';
```

### Safe Pattern
```sql
-- GOOD: Using parameterized queries
SELECT * FROM users WHERE email = ?;  -- Apply escaping/binding
```

## ğŸ” How to Interpret Results

### High Vulnerability Rate
- GPT tends to generate unsafe SQL
- Use with caution in production
- Always validate and sanitize generated code

### Low Vulnerability Rate
- GPT generates mostly safe SQL
- Still review code carefully
- Don't rely solely on AI for security

### CWE Patterns
- If CWE-89 dominant â†’ SQL injection is the main issue
- Mix of CWEs â†’ Multiple vulnerability types

## ğŸš¨ Important Notes

âš ï¸ **This is a research experiment**
- Results are for analysis purposes only
- Don't use generated SQL directly in production
- Always review AI-generated code carefully
- Apply security best practices (prepared statements, input validation)

âœ… **Best Practices**
- Use parameterized queries / prepared statements
- Validate and sanitize all user input
- Use ORM frameworks when possible
- Apply principle of least privilege
- Regular security audits

## ğŸ’¡ Extending the Experiment

### Try Different Models
Edit `experiment_main.py`:
```python
claude = ClaudeClient(model="claude-3-opus-20240229")
openai = OpenAIClient(model="gpt-4")
```

### Increase Sample Size
```bash
python -m src.experiment_main 100
```

### Modify Prompts
Edit `experiment_runner.py` `generate_prompts()` method to test different prompt styles.

## ğŸ“Š Example Results Summary

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Total Samples: 20
Vulnerable: 8 (40.0%)
Not Vulnerable: 11 (55.0%)
Errors: 1 (5.0%)

Top CWE Types:
- CWE-89: 6 instances
- CWE-564: 2 instances
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ“ Citation

If you use this experiment in research, cite as:

```bibtex
@misc{sql-injection-experiment,
  title={SQL Injection Vulnerability Experiment for GPT-3.5},
  author={Your Name},
  year={2024},
  howpublished={\url{https://github.com/yourusername/secure-code-gen}}
}
```

## ğŸ“§ Questions & Feedback

For questions or feedback:
1. Check `experiments/README.md` for detailed guide
2. Review generated `REPORT.md` for findings
3. Examine `experiment_results.json` for raw data

## ğŸ“„ License

MIT License - See LICENSE file for details

---

**Last Updated:** October 2024
**Status:** Ready for use
**Maintenance:** Active
