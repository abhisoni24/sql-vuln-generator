# Secure Code Generation - SQL Injection Vulnerability Experiment

A comprehensive experiment to test whether **GPT-3.5-turbo generates SQL code vulnerable to SQL injection attacks**.

## 🎯 Objective

Determine the prevalence and types of SQL injection vulnerabilities in SQL code generated by GPT-3.5-turbo when given natural language prompts.

## 🔬 Experiment Design

```
┌─────────────────────────────────────────────────────────────┐
│                    Experiment Workflow                      │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Claude 3.5 Sonnet                                         │
│  ↓                                                          │
│  Generate 20 natural language prompts for SQL              │
│  ↓                                                          │
│  [20 diverse SQL task descriptions]                        │
│  ↓                                                          │
│  GPT-3.5-turbo                                             │
│  ↓                                                          │
│  Generate SQL code for each prompt                         │
│  ↓                                                          │
│  [20 SQL code samples]                                     │
│  ↓                                                          │
│  Claude 3.5 Sonnet                                         │
│  ↓                                                          │
│  Analyze each SQL for CWE vulnerabilities                  │
│  ↓                                                          │
│  [Verdict + CWE ID for each sample]                        │
│  ↓                                                          │
│  Generate Visualizations                                   │
│  ↓                                                          │
│  [Charts, tables, detailed report]                         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## 📊 Key Findings (After Running)

The experiment will reveal:
- **Vulnerability Rate**: % of GPT-generated SQL with injection flaws
- **CWE Distribution**: Common vulnerability types
- **Code Patterns**: Safe vs unsafe SQL generation patterns
- **Practical Insights**: Real risks when using LLMs for SQL generation

## 🚀 Quick Start

### Prerequisites
- Python 3.8+
- API keys for Claude (Anthropic) and OpenAI

### 1. Clone & Setup

```bash
cd md-vuln-markdown-generator
cp .env.example .env
nano .env  # Add your API keys
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Experiment

```bash
# Quick start with 20 samples
python -m src.experiment_main

# Or specify custom number of samples
python -m src.experiment_main 50

# Or use the quick start script
bash quickstart.sh
```

### 4. View Results

Results are saved to `experiments/` directory:
- `experiment_results.json` - Raw data
- `REPORT.md` - Detailed markdown report
- `*.png` - Visualizations (charts and statistics)

## 📁 Project Structure

```
md-vuln-markdown-generator/
├── src/
│   ├── api/
│   │   ├── claude_client.py          # Claude API integration
│   │   └── openai_client.py          # OpenAI API integration
│   ├── experiment_runner.py          # Core experiment logic
│   ├── experiment_main.py            # CLI entry point
│   ├── visualizations.py             # Chart/graph generation
│   └── utils/
│       └── io.py                     # I/O utilities
├── experiments/                      # Output directory (created at runtime)
│   ├── README.md                     # Detailed experiment guide
│   ├── experiment_results.json       # Raw results (generated)
│   ├── REPORT.md                     # Report (generated)
│   └── *.png                         # Visualizations (generated)
├── .env                              # API keys (create from .env.example)
├── .env.example                      # Environment template
├── requirements.txt                  # Python dependencies
├── quickstart.sh                     # Quick start script
└── README.md                         # This file
```

## 🔑 API Configuration

### Claude (Anthropic)
1. Get key from: https://console.anthropic.com/account/keys
2. Add to `.env` as: `CLAUDE_API_KEY=sk-ant-...`
3. Model used: `claude-3-5-sonnet-20241022`

### OpenAI
1. Get key from: https://platform.openai.com/account/api-keys
2. Add to `.env` as: `OPENAI_API_KEY=sk-...`
3. Model used: `gpt-3.5-turbo`

## 📈 Output Visualizations

The experiment generates:

1. **Vulnerability Distribution** (Pie chart)
   - Shows % of vulnerable vs safe SQL code

2. **CWE Distribution** (Bar chart)
   - Common vulnerability types found

3. **Summary Statistics** (Info graphic)
   - Key metrics and findings

4. **Sample Showcase** (Multi-panel)
   - Examples of vulnerable and safe code

## 🛡️ Understanding Results

### Verdict Categories

| Verdict | Meaning |
|---------|---------|
| **VULNERABLE** | Potential SQL injection detected |
| **NOT VULNERABLE** | Code appears safe from injection |
| **ERROR** | Analysis could not complete |

### Common CWE IDs

| CWE | Type | Risk |
|-----|------|------|
| **CWE-89** | SQL Injection | Critical |
| **CWE-564** | SQL Injection (variant) | Critical |
| **CWE-90** | Improper Neutralization | High |

## 🐛 Troubleshooting

### "API key not found"
```bash
# Ensure .env file exists and has keys
cat .env | grep CLAUDE_API_KEY
cat .env | grep OPENAI_API_KEY
```

### "Module not found"
```bash
# Install dependencies
pip install -r requirements.txt

# Run from project root with -m flag
python -m src.experiment_main
```

### "Rate limit exceeded"
```bash
# Try again later or reduce sample size
python -m src.experiment_main 5
```

### "Matplotlib not found"
```bash
# Install optional visualization dependencies
pip install matplotlib
```

## 📚 Understanding SQL Injection

### Vulnerable Pattern
```sql
-- BAD: User input directly in query
SELECT * FROM users WHERE email = 'user@example.com OR 1=1 --';
```

### Safe Pattern
```sql
-- GOOD: Using parameterized queries
SELECT * FROM users WHERE email = ?;  -- Apply escaping/binding
```

## 🔍 How to Interpret Results

### High Vulnerability Rate
- GPT tends to generate unsafe SQL
- Use with caution in production
- Always validate and sanitize generated code

### Low Vulnerability Rate
- GPT generates mostly safe SQL
- Still review code carefully
- Don't rely solely on AI for security

### CWE Patterns
- If CWE-89 dominant → SQL injection is the main issue
- Mix of CWEs → Multiple vulnerability types

## 🚨 Important Notes

⚠️ **This is a research experiment**
- Results are for analysis purposes only
- Don't use generated SQL directly in production
- Always review AI-generated code carefully
- Apply security best practices (prepared statements, input validation)

✅ **Best Practices**
- Use parameterized queries / prepared statements
- Validate and sanitize all user input
- Use ORM frameworks when possible
- Apply principle of least privilege
- Regular security audits

## 💡 Extending the Experiment

### Try Different Models
Edit `experiment_main.py`:
```python
claude = ClaudeClient(model="claude-3-opus-20240229")
openai = OpenAIClient(model="gpt-4")
```

### Increase Sample Size
```bash
python -m src.experiment_main 100
```

### Modify Prompts
Edit `experiment_runner.py` `generate_prompts()` method to test different prompt styles.

## 📊 Example Results Summary

```
═══════════════════════════════════════════════════════════
Total Samples: 20
Vulnerable: 8 (40.0%)
Not Vulnerable: 11 (55.0%)
Errors: 1 (5.0%)

Top CWE Types:
- CWE-89: 6 instances
- CWE-564: 2 instances
═══════════════════════════════════════════════════════════
```

## 📝 Citation

If you use this experiment in research, cite as:

```bibtex
@misc{sql-injection-experiment,
  title={SQL Injection Vulnerability Experiment for GPT-3.5},
  author={Your Name},
  year={2024},
  howpublished={\url{https://github.com/yourusername/secure-code-gen}}
}
```

## 📧 Questions & Feedback

For questions or feedback:
1. Check `experiments/README.md` for detailed guide
2. Review generated `REPORT.md` for findings
3. Examine `experiment_results.json` for raw data

## 📄 License

MIT License - See LICENSE file for details

---

**Last Updated:** October 2024
**Status:** Ready for use
**Maintenance:** Active
